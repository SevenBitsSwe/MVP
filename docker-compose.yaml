services:
  zookeeper:
    hostname: zookeeper
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:7.6.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 2181:2181
    healthcheck:
      test: nc -z localhost 2181 || exit -1
      interval: 10s
      timeout: 5s
      retries: 3
    profiles: ["test","develop","prod"]

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    hostname: kafka
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
      clickhouse:
        condition: service_started
    ports:
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_ADVERTISED_HOST_NAME: "kafka"
    command:
      - sh
      - -c
      - |
        # Rimuovi i nodi esistenti di Kafka in Zookeeper
        echo "deleteall /brokers/ids/1" | /usr/bin/zookeeper-shell zookeeper:2181 || true
        # Avvia Kafka e crea i topic
        /etc/confluent/docker/run &
        kafka-topics --create --topic MessageElaborated --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1
        kafka-topics --create --topic SimulatorPosition --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1
        wait
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "kafka-topics --bootstrap-server localhost:29092 --list | grep -q 'MessageElaborated' && kafka-topics --bootstrap-server localhost:29092 --list | grep -q 'SimulatorPosition'",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    profiles: ["test","develop","prod"]

  kafdrop:
    container_name: kafdrop
    image: obsidiandynamics/kafdrop
    restart: "no"
    ports:
      - "9080:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:9092"
    depends_on:
      kafka:
        condition: service_healthy
    profiles: ["develop","prod"]

  grafana:
    container_name: grafana
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_INSTALL_PLUGINS: "grafana-clickhouse-datasource" # Plugin ClickHouse
    volumes:
      - ./Grafana/DashboardProv:/etc/grafana/provisioning/dashboards # Configurazione provider dashboard # dashboard.yml
      - ./Grafana/Dashboards:/var/lib/grafana/dashboards # Configurazione dashboard # dashboard.json
      - ./Grafana/DatasourceProv:/etc/grafana/provisioning/datasources # Configurazione datasource # datasources.yml
    profiles: ["develop","prod"]

  # clickhouse:
  #   image: bitnami/clickhouse:latest
  #   # image: yandex/clickhouse-server:latest
  #   environment:
  #     CLICKHOUSE_ADMIN_USER: default
  #     CLICKHOUSE_ADMIN_PASSWORD: pass
  #     ALLOW_EMPTY_PASSWORD: no
  #   volumes:
  #      - ./StorageData/override.xml:/bitnami/clickhouse/etc/conf.d/override.xml:ro
  #      - ./StorageData:/docker-entrypoint-initdb.d/

  #     # - ./config.xml:/opt/bitnami/clickhouse/etc/config.xml
  #   # container_name: clickhouse
  #   ports:
  #     - 8123:8123 # HTTP
  #     - 9000:9000 # Native

  clickhouse:
    image: clickhouse/clickhouse-server:24.10
    hostname: clickhouse
    container_name: clickhouse
    ports:
      - "8123:8123"
      - "9000:9000"
    environment:
      CLICKHOUSE_DB: nearyou
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: pass # Password per l'utente
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 0 # Abilita la gestione accessi
    volumes:
      - ./StorageData:/docker-entrypoint-initdb.d
    profiles: ["test","develop","prod"]

  positionsimulator:
    container_name: positions
    build: ./SimulationModule
    # mem_limit: 4G # Limita la memoria a 2GB
    depends_on:
      kafka:
        condition: service_healthy
    profiles: ["test","develop","prod"]
  flink:
    container_name: flink
    build: ./FlinkProcessor
    volumes:
      - .env:/app/.env
    restart: on-failure:5
    deploy:
      resources:
        limits:
          cpus: '4.00'
          memory: 4G
    depends_on:
      kafka:
        condition: service_healthy
    profiles: ["test","develop","prod"]

  test:
    container_name: test
    build: 
      context: ./
      dockerfile: Tests/Dockerfile
    depends_on:
      kafka:
        condition: service_healthy
    profiles: ["test"]